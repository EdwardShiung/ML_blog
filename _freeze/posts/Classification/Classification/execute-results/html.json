{
  "hash": "ef184497be6d730a3b951ff1be653695",
  "result": {
    "markdown": "---\ntitle: Classification\ntitle-block-banner: false\nauthor: Edward Xiong\ndate: '2023-11-05'\ndescription: Using Heart Disease Dataset to Predict the Patient by Classification\nformat:\n  html:\n    toc: true\n    toc-location: right\ncategories:\n  - Statistics\n  - Python\n  - Machine Learning\nimage: ../../assets/classification.jpg\ncomments:\n  giscus:\n    repo: EdwardShiung/ml_CS5805\n---\n\n# Introduction\nMachine Learning process can be outlined as follow:\n\n1. Problem Definition\n    - What problem are we trying to solve? \n2. Data\n    - What data do we have? Do we need to do data cleaning?\n3. Evalution\n    - Which problem define well?\n4. Features\n    - What feature should we model?\n5. Modelling\n    - What kind of model should we use?\n6. Experiment\n    - Which model is suitable? How can we tune our model?\n\nOnce we define the problem, we could also know which questions could be classified the type of estimator. Here will provide a brieft estimator map for solving machine leaning problem.\n\nhttps://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n\n## Problem Definition\nOur case is about heart disease predict. The problem is be solved by the **binary classification**.\n\nIn a statement,\n\n> Based on clinical parameters for a patient, can we predict whether or not they have heart disease?\n\n## Libraries Section:\n\n* [pandas](https://pandas.pydata.org/)\n* [NumPy](https://numpy.org/)\n* [Matplotlib](https://matplotlib.org/)\n* [seaborn](https://seaborn.pydata.org/) \n* [Scikit-Learn](https://scikit-learn.org/stable/) \n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n:::\n\n\n## Models\nAbove question let us know that we will use classification, and we could take a reference from [Scikit-Learn Map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) to choose model we want to compare.\n\nIn our cases, we choose Logistic Regression model, KNN model, and Random Forest Classifer.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n```\n:::\n\n\n## Model Evalution Library\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n```\n:::\n\n\n## Data\nThe origin data comes from the UCI Machine Learning Repository. \n>Here is the link: https://archive.ics.uci.edu/ml/datasets/heart+Disease\n\nIn addition, we found this data from Kaggle.\n>Here is the link: https://www.kaggle.com/datasets/sumaiyatasmeem/heart-disease-classification-dataset\n\nThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.\n\nSo here, we create the data dictionary:\n\n**Data Dictionary**\n\n1. age - age in years\n2. sex - (1 = male; 0 = female)\n3. cp - chest pain type\n    * 0: Typical angina: chest pain related decrease blood supply to the heart\n    * 1: Atypical angina: chest pain not related to heart\n    * 2: Non-anginal pain: typically esophageal spasms (non heart related)\n    * 3: Asymptomatic: chest pain not showing signs of disease\n4. trestbps - resting blood pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern\n5. chol - serum cholestoral in mg/dl\n    * serum = LDL + HDL + .2 * triglycerides\n    * above 200 is cause for concern\n6. fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n    * '>126' mg/dL signals diabetes\n7. restecg - resting electrocardiographic results\n    * 0: Nothing to note\n    * 1: ST-T Wave abnormality\n        * can range from mild symptoms to severe problems\n        * signals non-normal heart beat\n    * 2: Possible or definite left ventricular hypertrophy\n        * Enlarged heart's main pumping chamber\n8. thalach - maximum heart rate achieved\n9. exang - exercise induced angina (1 = yes; 0 = no)\n10. oldpeak - ST depression induced by exercise relative to rest looks at stress of heart during excercise unhealthy heart will stress more\n11. slope - the slope of the peak exercise ST segment\n    * 0: Upsloping: better heart rate with excercise (uncommon)\n    * 1: Flatsloping: minimal change (typical healthy heart)\n    * 2: Downslopins: signs of unhealthy heart\n12. ca - number of major vessels (0-3) colored by flourosopy\n    * colored vessel means the doctor can see the blood passing through\n    * the more blood movement the better (no clots)\n13. thal - thalium stress result\n    * 1,3: normal\n    * 6: fixed defect: used to be defect but ok now\n    * 7: reversable defect: no proper blood movement when excercising\n14. target - have disease or not (1=yes, 0=no) (= the predicted attribute)\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndf = pd.read_csv('../../dataset/HeartDisease/heart-disease.csv');\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140</td>\n      <td>241</td>\n      <td>0</td>\n      <td>1</td>\n      <td>123</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>1</td>\n      <td>132</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>1</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 14 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Explore Data Analysis (EDA)\n\nOnce we've imported dataset, we could start to explore the dataset to find some pattern. When we get a dataset, it's hard to tell and understand the situation. That's why we do some visualization for prelimary research questions in the beginning, and then, we can observer the correletion between independent variables and dependent variables. \n\nHere, we want to fouce on the 3 classification algorithms applying in our cases, so we will breeze throught it and just demonstrate one situation to find a pattern. For example:\n\n> Does chest pain (cp), age, or other attributes relate to whether or not someone has heart disease?\n\nIn the above hypothesis, we could use **correletion matrix**. \n\nSo, **what's correletion matrix?** It's a big table telling us how each independent variable is related to each other.\n\nps. You can take above reference to know what is cp.\n\n### Correletion Matrix\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndf.corr()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>1.000000</td>\n      <td>-0.098447</td>\n      <td>-0.068653</td>\n      <td>0.279351</td>\n      <td>0.213678</td>\n      <td>0.121308</td>\n      <td>-0.116211</td>\n      <td>-0.398522</td>\n      <td>0.096801</td>\n      <td>0.210013</td>\n      <td>-0.168814</td>\n      <td>0.276326</td>\n      <td>0.068001</td>\n      <td>-0.225439</td>\n    </tr>\n    <tr>\n      <th>sex</th>\n      <td>-0.098447</td>\n      <td>1.000000</td>\n      <td>-0.049353</td>\n      <td>-0.056769</td>\n      <td>-0.197912</td>\n      <td>0.045032</td>\n      <td>-0.058196</td>\n      <td>-0.044020</td>\n      <td>0.141664</td>\n      <td>0.096093</td>\n      <td>-0.030711</td>\n      <td>0.118261</td>\n      <td>0.210041</td>\n      <td>-0.280937</td>\n    </tr>\n    <tr>\n      <th>cp</th>\n      <td>-0.068653</td>\n      <td>-0.049353</td>\n      <td>1.000000</td>\n      <td>0.047608</td>\n      <td>-0.076904</td>\n      <td>0.094444</td>\n      <td>0.044421</td>\n      <td>0.295762</td>\n      <td>-0.394280</td>\n      <td>-0.149230</td>\n      <td>0.119717</td>\n      <td>-0.181053</td>\n      <td>-0.161736</td>\n      <td>0.433798</td>\n    </tr>\n    <tr>\n      <th>trestbps</th>\n      <td>0.279351</td>\n      <td>-0.056769</td>\n      <td>0.047608</td>\n      <td>1.000000</td>\n      <td>0.123174</td>\n      <td>0.177531</td>\n      <td>-0.114103</td>\n      <td>-0.046698</td>\n      <td>0.067616</td>\n      <td>0.193216</td>\n      <td>-0.121475</td>\n      <td>0.101389</td>\n      <td>0.062210</td>\n      <td>-0.144931</td>\n    </tr>\n    <tr>\n      <th>chol</th>\n      <td>0.213678</td>\n      <td>-0.197912</td>\n      <td>-0.076904</td>\n      <td>0.123174</td>\n      <td>1.000000</td>\n      <td>0.013294</td>\n      <td>-0.151040</td>\n      <td>-0.009940</td>\n      <td>0.067023</td>\n      <td>0.053952</td>\n      <td>-0.004038</td>\n      <td>0.070511</td>\n      <td>0.098803</td>\n      <td>-0.085239</td>\n    </tr>\n    <tr>\n      <th>fbs</th>\n      <td>0.121308</td>\n      <td>0.045032</td>\n      <td>0.094444</td>\n      <td>0.177531</td>\n      <td>0.013294</td>\n      <td>1.000000</td>\n      <td>-0.084189</td>\n      <td>-0.008567</td>\n      <td>0.025665</td>\n      <td>0.005747</td>\n      <td>-0.059894</td>\n      <td>0.137979</td>\n      <td>-0.032019</td>\n      <td>-0.028046</td>\n    </tr>\n    <tr>\n      <th>restecg</th>\n      <td>-0.116211</td>\n      <td>-0.058196</td>\n      <td>0.044421</td>\n      <td>-0.114103</td>\n      <td>-0.151040</td>\n      <td>-0.084189</td>\n      <td>1.000000</td>\n      <td>0.044123</td>\n      <td>-0.070733</td>\n      <td>-0.058770</td>\n      <td>0.093045</td>\n      <td>-0.072042</td>\n      <td>-0.011981</td>\n      <td>0.137230</td>\n    </tr>\n    <tr>\n      <th>thalach</th>\n      <td>-0.398522</td>\n      <td>-0.044020</td>\n      <td>0.295762</td>\n      <td>-0.046698</td>\n      <td>-0.009940</td>\n      <td>-0.008567</td>\n      <td>0.044123</td>\n      <td>1.000000</td>\n      <td>-0.378812</td>\n      <td>-0.344187</td>\n      <td>0.386784</td>\n      <td>-0.213177</td>\n      <td>-0.096439</td>\n      <td>0.421741</td>\n    </tr>\n    <tr>\n      <th>exang</th>\n      <td>0.096801</td>\n      <td>0.141664</td>\n      <td>-0.394280</td>\n      <td>0.067616</td>\n      <td>0.067023</td>\n      <td>0.025665</td>\n      <td>-0.070733</td>\n      <td>-0.378812</td>\n      <td>1.000000</td>\n      <td>0.288223</td>\n      <td>-0.257748</td>\n      <td>0.115739</td>\n      <td>0.206754</td>\n      <td>-0.436757</td>\n    </tr>\n    <tr>\n      <th>oldpeak</th>\n      <td>0.210013</td>\n      <td>0.096093</td>\n      <td>-0.149230</td>\n      <td>0.193216</td>\n      <td>0.053952</td>\n      <td>0.005747</td>\n      <td>-0.058770</td>\n      <td>-0.344187</td>\n      <td>0.288223</td>\n      <td>1.000000</td>\n      <td>-0.577537</td>\n      <td>0.222682</td>\n      <td>0.210244</td>\n      <td>-0.430696</td>\n    </tr>\n    <tr>\n      <th>slope</th>\n      <td>-0.168814</td>\n      <td>-0.030711</td>\n      <td>0.119717</td>\n      <td>-0.121475</td>\n      <td>-0.004038</td>\n      <td>-0.059894</td>\n      <td>0.093045</td>\n      <td>0.386784</td>\n      <td>-0.257748</td>\n      <td>-0.577537</td>\n      <td>1.000000</td>\n      <td>-0.080155</td>\n      <td>-0.104764</td>\n      <td>0.345877</td>\n    </tr>\n    <tr>\n      <th>ca</th>\n      <td>0.276326</td>\n      <td>0.118261</td>\n      <td>-0.181053</td>\n      <td>0.101389</td>\n      <td>0.070511</td>\n      <td>0.137979</td>\n      <td>-0.072042</td>\n      <td>-0.213177</td>\n      <td>0.115739</td>\n      <td>0.222682</td>\n      <td>-0.080155</td>\n      <td>1.000000</td>\n      <td>0.151832</td>\n      <td>-0.391724</td>\n    </tr>\n    <tr>\n      <th>thal</th>\n      <td>0.068001</td>\n      <td>0.210041</td>\n      <td>-0.161736</td>\n      <td>0.062210</td>\n      <td>0.098803</td>\n      <td>-0.032019</td>\n      <td>-0.011981</td>\n      <td>-0.096439</td>\n      <td>0.206754</td>\n      <td>0.210244</td>\n      <td>-0.104764</td>\n      <td>0.151832</td>\n      <td>1.000000</td>\n      <td>-0.344029</td>\n    </tr>\n    <tr>\n      <th>target</th>\n      <td>-0.225439</td>\n      <td>-0.280937</td>\n      <td>0.433798</td>\n      <td>-0.144931</td>\n      <td>-0.085239</td>\n      <td>-0.028046</td>\n      <td>0.137230</td>\n      <td>0.421741</td>\n      <td>-0.436757</td>\n      <td>-0.430696</td>\n      <td>0.345877</td>\n      <td>-0.391724</td>\n      <td>-0.344029</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Visualized Correletion Matrix by Heatmap\ncorreletion_matrix = df.corr()\nfig, ax = plt.subplots(figsize = (12, 9));\nax = sns.heatmap(correletion_matrix,\n                 annot = True,\n                 fmt = '.2f',\n                 cmap = 'YlOrRd');\n```\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-7-output-1.png){width=917 height=712}\n:::\n:::\n\n\nA higher positve value means a potential possitive correletion; a higher negative means a potential negative correletion.\n\nSo, based on the contribution matrix, as \"cp\" goes up, the \"target value\" should also goes up.\n\nWe can do a basic graph to visualize the relation between cp and target.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Crosstab for cp and target\npd.crosstab(df.cp, df.target).plot(kind = 'bar',\n                                   figsize = (12, 9),\n                                   color = ['lightblue', 'salmon']);\nplt.title('Heart Disease Frequence');\nplt.xlabel('Chest Pain Type');\nplt.ylabel('Amount');\nplt.legend(['No Disease', 'Disease']);\nplt.xticks(rotation = 0);\n```\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-8-output-1.png){width=965 height=745}\n:::\n:::\n\n\nEven though, Chest Pain Type 3 goes down, the ratio of disease to no disease is still much higher. \n\nCorrelation Matrix could be a insight that we want to sort of figure out on our own. This is the purpose of EDA.\n\n## Preparing Data for Machine Learning Model\n\nBefore Modeling, we need to do two things:\n\n1. Split the dataset into features & labels\n2. Split the dataset into trainning dataset & testing dataset\n\nWhy? \n\nFirst, because we want to do binary classification, spliting the dataset into features and labels is very important.\nSecond, if we don't split the dataset into trainning dataset & testing dataset, how would you know know how well your model goes on a new patient not included in the original full data?\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Split the dataset into features and label\nX = df.drop('target', axis = 1);\ny = df['target']\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nX\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140</td>\n      <td>241</td>\n      <td>0</td>\n      <td>1</td>\n      <td>123</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>1</td>\n      <td>132</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>1</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 13 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n0      1\n1      1\n2      1\n3      1\n4      1\n      ..\n298    0\n299    0\n300    0\n301    0\n302    0\nName: target, Length: 303, dtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n# Split the dataset into trainning dataset & testing dataset\nnp.random.seed(24)\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)\n```\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nX_train\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105</th>\n      <td>68</td>\n      <td>0</td>\n      <td>2</td>\n      <td>120</td>\n      <td>211</td>\n      <td>0</td>\n      <td>0</td>\n      <td>115</td>\n      <td>0</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>44</td>\n      <td>1</td>\n      <td>0</td>\n      <td>110</td>\n      <td>197</td>\n      <td>0</td>\n      <td>0</td>\n      <td>177</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>66</td>\n      <td>0</td>\n      <td>0</td>\n      <td>178</td>\n      <td>228</td>\n      <td>1</td>\n      <td>1</td>\n      <td>165</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>63</td>\n      <td>0</td>\n      <td>1</td>\n      <td>140</td>\n      <td>195</td>\n      <td>0</td>\n      <td>1</td>\n      <td>179</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>58</td>\n      <td>1</td>\n      <td>2</td>\n      <td>112</td>\n      <td>230</td>\n      <td>0</td>\n      <td>0</td>\n      <td>165</td>\n      <td>0</td>\n      <td>2.5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>207</th>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>150</td>\n      <td>258</td>\n      <td>0</td>\n      <td>0</td>\n      <td>157</td>\n      <td>0</td>\n      <td>2.6</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>54</td>\n      <td>0</td>\n      <td>2</td>\n      <td>108</td>\n      <td>267</td>\n      <td>0</td>\n      <td>0</td>\n      <td>167</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>74</td>\n      <td>0</td>\n      <td>1</td>\n      <td>120</td>\n      <td>269</td>\n      <td>0</td>\n      <td>0</td>\n      <td>121</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>70</td>\n      <td>1</td>\n      <td>1</td>\n      <td>156</td>\n      <td>245</td>\n      <td>0</td>\n      <td>0</td>\n      <td>143</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>54</td>\n      <td>1</td>\n      <td>0</td>\n      <td>120</td>\n      <td>188</td>\n      <td>0</td>\n      <td>1</td>\n      <td>113</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>242 rows × 13 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nX_test\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>202</th>\n      <td>58</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>270</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111</td>\n      <td>1</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>60</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>253</td>\n      <td>0</td>\n      <td>1</td>\n      <td>144</td>\n      <td>1</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>45</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112</td>\n      <td>160</td>\n      <td>0</td>\n      <td>1</td>\n      <td>138</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>218</th>\n      <td>65</td>\n      <td>1</td>\n      <td>0</td>\n      <td>135</td>\n      <td>254</td>\n      <td>0</td>\n      <td>0</td>\n      <td>127</td>\n      <td>0</td>\n      <td>2.8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>47</td>\n      <td>1</td>\n      <td>2</td>\n      <td>138</td>\n      <td>257</td>\n      <td>0</td>\n      <td>0</td>\n      <td>156</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>50</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>243</td>\n      <td>0</td>\n      <td>0</td>\n      <td>128</td>\n      <td>0</td>\n      <td>2.6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>54</td>\n      <td>1</td>\n      <td>0</td>\n      <td>110</td>\n      <td>206</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>54</td>\n      <td>1</td>\n      <td>2</td>\n      <td>120</td>\n      <td>258</td>\n      <td>0</td>\n      <td>0</td>\n      <td>147</td>\n      <td>0</td>\n      <td>0.4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>61</td>\n      <td>1</td>\n      <td>0</td>\n      <td>148</td>\n      <td>203</td>\n      <td>0</td>\n      <td>1</td>\n      <td>161</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>64</td>\n      <td>1</td>\n      <td>3</td>\n      <td>170</td>\n      <td>227</td>\n      <td>0</td>\n      <td>0</td>\n      <td>155</td>\n      <td>0</td>\n      <td>0.6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>61 rows × 13 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ny_train\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n105    1\n200    0\n260    0\n102    1\n183    0\n      ..\n207    0\n123    1\n129    1\n145    1\n192    0\nName: target, Length: 242, dtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ny_test\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n202    0\n186    0\n94     1\n218    0\n47     1\n      ..\n184    0\n264    0\n70     1\n290    0\n152    1\nName: target, Length: 61, dtype: int64\n```\n:::\n:::\n\n\nNow we've had our data split into training and testing dataset, and we could use 3 different machine learning models to demonstrate the preliminary model.\n\n1. Logistic Regression\n2. K-Neareast Neighbors Classifer\n3. Random Forest Classifier\n\nIn this note, we just compare 3 different classification models, so we don't do tuning the model find the important feature or others.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n# Save Model Score\nM_Score = {};\n```\n:::\n\n\n### Logistic Regression Model\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# Set Random Seed\nnp.random.seed(24);\n\n# Logistic Regression Model\nlog_reg_model = {'Logistic Regression': LogisticRegression()};\n\n# Fit the model to the training data\nkey = list(log_reg_model.keys())[0];\nvalue = log_reg_model[key];\nvalue.fit(X_train, y_train);\nM_Score [key] = value.score(X_test, y_test);\n\nM_Score\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/tianyu/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning:\n\nlbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n{'Logistic Regression': 0.8688524590163934}\n```\n:::\n:::\n\n\n### KNN Model\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n# Set Random Seed\nnp.random.seed(24);\n\n# KNN Model\nlog_reg_model = {'KNN': KNeighborsClassifier()};\n\n# Fit the model to the training data\nkey = list(log_reg_model.keys())[0];\nvalue = log_reg_model[key];\nvalue.fit(X_train, y_train);\nM_Score [key] = value.score(X_test, y_test);\n\nM_Score\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n{'Logistic Regression': 0.8688524590163934, 'KNN': 0.6721311475409836}\n```\n:::\n:::\n\n\n### Random Forest Model\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n# Set Random Seed\nnp.random.seed(24);\n\n# KNN Model\nlog_reg_model = {'Random Forest': RandomForestClassifier()};\n\n# Fit the model to the training data\nkey = list(log_reg_model.keys())[0];\nvalue = log_reg_model[key];\nvalue.fit(X_train, y_train);\nM_Score [key] = value.score(X_test, y_test);\n\nM_Score\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n{'Logistic Regression': 0.8688524590163934,\n 'KNN': 0.6721311475409836,\n 'Random Forest': 0.8688524590163934}\n```\n:::\n:::\n\n\n### Model Comparison\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nM_Compare = pd.DataFrame(M_Score, index = ['Accuracy Score']);\nM_Compare.T.plot.bar();\nplt.xticks(rotation = 0);\n```\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-21-output-1.png){width=571 height=411}\n:::\n:::\n\n\nHere, we get the accuracy score for 3 different models. As you can see, this is the preliminary results by 3 different models. If we want the result fall into 95% or higher, we need to know tuning or finding important features.\n\n",
    "supporting": [
      "Classification_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}